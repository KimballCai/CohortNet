{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958315a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:10:37.437404Z",
     "start_time": "2023-07-18T07:10:36.277408Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset import DatasetConfig, MIMIC3SetLoader\n",
    "from model import CohortNet\n",
    "\n",
    "from util import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# define env setting\n",
    "sets = ['train', 'valid', 'test']\n",
    "\n",
    "\n",
    "def set_random_seed(seed=2000):\n",
    "    logging.info(\"[*]random seed: %d\" % seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  # cpu\n",
    "    torch.cuda.manual_seed(seed)  # gpu\n",
    "    torch.backends.cudnn.deterministic = True  # cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a14abf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:10:37.536270Z",
     "start_time": "2023-07-18T07:10:37.439490Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "    def __init__(self, args):\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        args = calculate_warm(args)\n",
    "        self.args = args\n",
    "        # print(self.args)\n",
    "\n",
    "        # the gpu setting\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(self.args.gpu)\n",
    "\n",
    "        self.set_config()\n",
    "\n",
    "        # get the file path for the logging\n",
    "        log_root = \"Please update the url for log file\"\n",
    "        if os.path.exists(log_root):\n",
    "            self.log_root = log_root\n",
    "        else:\n",
    "            raise FileNotFoundError(\"[x] Log path does not exist.\")\n",
    "        # if not os.path.exists(self.log_root):\n",
    "        #     os.mkdir(self.log_root)\n",
    "        # self.log_root = os.path.abspath(os.path.dirname(__file__)) + \"/logs/\"\n",
    "        self.log_path = self.set_log_path(timestamp)\n",
    "\n",
    "        # the logger setting\n",
    "        handlers = [logging.FileHandler(self.log_path + 'log_{}.txt'.format(timestamp), mode='w'),\n",
    "                    logging.StreamHandler()]\n",
    "        logging.basicConfig(level=logging.INFO, datefmt='%m-%d-%y %H:%M', format='%(asctime)s:%(message)s',\n",
    "                            handlers=handlers)\n",
    "        logging.info(\"================== Start %s ==================\"%timestamp)\n",
    "\n",
    "        # set the random seed\n",
    "        if not self.args.random:\n",
    "            random_seed = 2000\n",
    "        else:\n",
    "            random_seed = np.random.randint(10e6)\n",
    "        set_random_seed(random_seed)\n",
    "\n",
    "        logging.info('Timestamp: {}'.format(timestamp))\n",
    "        logging.info('Arguments')\n",
    "        for k, v in sorted(vars(self.args).items()):\n",
    "            logging.info(\"%s = %s\" % (k, str(v)))\n",
    "\n",
    "        self.learning()\n",
    "\n",
    "    def set_config(self):\n",
    "        # for binary-label classification\n",
    "        self.metrics = ['bceloss', 'auroc', 'auprc', 'accu', 'f1', 'minpse']\n",
    "        self.train_mode = \"SP\"\n",
    "\n",
    "    def learning(self):\n",
    "        for i_fold in self.args.folds:\n",
    "            logging.info('============= {}-th fold ============='.format(i_fold))\n",
    "            self.dataset = {}\n",
    "            for name in sets:\n",
    "                self.dataset[name] = self.set_dataset(name, i_fold)\n",
    "            self.input_dim = self.dataset['train'].input_dim\n",
    "            self.output_dim = self.dataset['train'].output_dim\n",
    "            self.set_model(self.args)\n",
    "            self.recorders = Recorders(sets, self.metrics, args.patience)\n",
    "\n",
    "            if self.args.mode == \"train\":\n",
    "                self.criterion = self.set_criterion(type=self.args.criterion)\n",
    "                self.writer = SummaryWriter(self.log_path)\n",
    "                for epoch in range(1, self.args.epochs+1):\n",
    "                    adjust_learning_rate(self.args, self.optimizer, epoch)\n",
    "\n",
    "                    time1 = time.time()\n",
    "                    loss = self.train(epoch)\n",
    "                    time2 = time.time()\n",
    "                    save_flag, results = self.validate(epoch)\n",
    "                    time3 = time.time()\n",
    "                    logging.info('Epoch {}, lr {:.6f}, train loss {:.4f}, '\n",
    "                                 'train time {:.2f}s, valid time {:.2f}s, total time {:.2f}s.'.format(\n",
    "                        epoch,\n",
    "                        self.optimizer.param_groups[0]['lr'],\n",
    "                        loss,\n",
    "                        time2 - time1,\n",
    "                        time3 - time2,\n",
    "                        time3 - time1\n",
    "                    ))\n",
    "                    logging.info(self.recorders.to_string())\n",
    "                    # save results\n",
    "                    for subset in range(len(self.recorders.sets)):\n",
    "                        for m in range(len(self.recorders.metrics)):\n",
    "                            self.writer.add_scalar(tag=\"%s/%s/%s\" % (self.train_mode,\n",
    "                                                                     self.recorders.sets[subset],\n",
    "                                                                     self.recorders.metrics[m]),\n",
    "                                                   scalar_value=results[subset, m], global_step=epoch)\n",
    "                    if save_flag == 1:\n",
    "                        self.save_results(epoch, i_fold, results)\n",
    "                    elif save_flag == 0:\n",
    "                        logging.info(\"[*] Overfitting... Stop!\")\n",
    "                        break\n",
    "\n",
    "                self.eval_model(os.path.join(self.log_path, 'ckpt_{i}.pth'.format(i=i_fold)))\n",
    "\n",
    "            elif self.args.mode == \"eval\":\n",
    "                assert self.args.model_path != \"#\", \"[x] Please provide a valid model path!\"\n",
    "                if not os.path.exists(args.model_path):\n",
    "                    logging.info(\"[x] Model path is invalid: %s\" % self.args.model_path)\n",
    "                self.eval_model(args.model_path)\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        batch_time = []\n",
    "        total_steps = (self.dataset['train'].sample_size-1)//self.args.batch_size+1\n",
    "        for batch_id, batch_x, batch_y in self.dataset['train'].get_generator(self.args.batch_size, shuffle=True):\n",
    "            start = time.time()\n",
    "            warmup_learning_rate(self.args, epoch, batch_id+1, total_steps, self.optimizer)\n",
    "\n",
    "            # info = torch.tensor(batch_x[0]).float()\n",
    "            label = torch.tensor(batch_y).float()\n",
    "            tdata = torch.tensor(batch_x[1]).float()\n",
    "            tmask = torch.tensor(batch_x[2]).float()\n",
    "            if self.args.dataset_mode == \"regular\":\n",
    "                stime = torch.tensor(batch_x[3]).float()\n",
    "                if torch.cuda.is_available():\n",
    "                    stime = stime.cuda()\n",
    "            else:  # irregular\n",
    "                stime = torch.tensor(batch_x[3]).float()\n",
    "                tlength = torch.tensor(batch_x[4]).float()\n",
    "                if torch.cuda.is_available():\n",
    "                    stime = stime.cuda()\n",
    "                    tlength = tlength.cuda()\n",
    "            if torch.cuda.is_available():\n",
    "                # info = info.cuda()\n",
    "                tdata = tdata.cuda()\n",
    "                tmask = tmask.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "            if self.args.model in [\"CohortNet\"]:\n",
    "                out = self.model([tdata, tmask])\n",
    "                # prediction\n",
    "                prediction = out[0]\n",
    "                # representation\n",
    "                rep = out[1]\n",
    "            loss = self.criterion(prediction, label)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # optimize\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            end = time.time()\n",
    "            batch_time.append(end - start)\n",
    "\n",
    "            if batch_id % self.args.print_freq == 0:\n",
    "                logging.info('Train: [{0}][{1}/{2}]\\t'\n",
    "                             'BT avg {batch_time:.3f}\\t'\n",
    "                             'loss avg {loss:.4f}'.format(\n",
    "                    epoch, batch_id, total_steps, batch_time=np.average(batch_time), loss=np.average(losses))\n",
    "                )\n",
    "        return np.average(losses)\n",
    "\n",
    "    def validate(self, epoch=-1):\n",
    "        self.model.eval()\n",
    "        results = {}\n",
    "        with torch.no_grad():\n",
    "            for set in self.recorders.sets:\n",
    "                sub_pred, sub_label = [], []\n",
    "                for batch_id, batch_x, batch_y in self.dataset[set].get_generator(self.args.batch_size, shuffle=False):\n",
    "                    tdata = torch.tensor(batch_x[1]).float()\n",
    "                    tmask = torch.tensor(batch_x[2]).float()\n",
    "                    if torch.cuda.is_available():\n",
    "                        tdata = tdata.cuda()\n",
    "                        tmask = tmask.cuda()\n",
    "\n",
    "                    if self.args.model in [\"CohortNet\"]:\n",
    "                        out = self.model([tdata, tmask])\n",
    "                        # prediction\n",
    "                        prediction = out[0]\n",
    "                        # representation\n",
    "                        rep = out[1]\n",
    "\n",
    "                    pred = prediction\n",
    "                    if torch.cuda.is_available():\n",
    "                        pred = pred.cpu()\n",
    "\n",
    "                    sub_pred.extend(list(pred.detach().numpy()))\n",
    "                    sub_label.extend(batch_y)\n",
    "                results[set] = binary_eval(y_true=sub_label, y_pred=sub_pred)\n",
    "        save_flag = self.recorders.insert(results)\n",
    "        return save_flag, self.recorders.get_epoch_result()\n",
    "\n",
    "    def set_dataset(self, name, i_fold):\n",
    "        assert name in ['train', 'valid', 'test'], \"[x] No such dataset mode: %s\" % name\n",
    "        from dataset import DatasetConfig\n",
    "        config = DatasetConfig(set_name=self.args.dataset)\n",
    "        if self.args.dataset == \"MIMIC3\":\n",
    "            logging.info(\"[*]loading the MIMIC3 dataset: %s.\"%name)\n",
    "            from dataset import MIMIC3SetLoader\n",
    "            return MIMIC3SetLoader(self.args, name, config, i_fold)\n",
    "        else:\n",
    "            raise NotImplementedError(\"[x] cannot support the dataset: %s\"%self.args.dataset)\n",
    "\n",
    "    def set_criterion(self, type=\"bce\"):\n",
    "        assert type in ['bce'], \"[x] No such criterion: %s\" % type\n",
    "        if type == \"bce\":\n",
    "            criterion = torch.nn.BCELoss()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            if torch.cuda.device_count() > 1 and len(self.args.gpu) > 1:\n",
    "                criterion = criterion.cuda()\n",
    "        return criterion\n",
    "\n",
    "    def set_model(self, args):\n",
    "        if self.args.dataset_mode == \"regular\":\n",
    "            if self.args.model == \"CohortNet\":\n",
    "                from model import CohortNet\n",
    "                model = CohortNet(o_dim=self.output_dim, f_num=self.input_dim, e_dim=args.embed_dim, c_dim=args.compress_dim,\n",
    "                                  h_dim=args.hidden_dim, fusion_dim=args.fusion_dim, cluster_num=args.k,\n",
    "                                  clip_min=args.clip_min, clip_max=args.clip_max, active=args.active)\n",
    "        else:\n",
    "            raise NotImplementedError(\"No such mode: %s\" % (args.dataset_mode))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            if torch.cuda.device_count() > 1 and len(args.gpu) > 1:\n",
    "                model = torch.nn.DataParallel(model)\n",
    "\n",
    "            model = model.cuda()\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        assert self.args.opt in ['adam', 'sgd'], \"[x] No such optimizer: %s\" % self.args.opt\n",
    "        if self.args.opt == 'sgd':\n",
    "            optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                        lr=self.args.lr,\n",
    "                                        momentum=self.args.momentum,\n",
    "                                        weight_decay=self.args.weight_decay)\n",
    "            logging.info(\"[*] optimizer: SGD, lr: %f, momentum: %f, weight decay: %f\" % (args.lr,\n",
    "                                                                                         self.args.momentum,\n",
    "                                                                                         self.args.weight_decay))\n",
    "        elif self.args.opt == 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=self.args.weight_decay)\n",
    "            logging.info(\"[*] optimizer: Adam, lr: %f, weight decay: %f\" % (args.lr, self.args.weight_decay))\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        logging.info(model)\n",
    "        total_num = sum(p.numel() for p in model.parameters())\n",
    "        trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        logging.info(\"Model param num: %d  trainable: %d\" % (total_num, trainable_num))\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # load pretrained parameters\n",
    "        if self.args.model_path != \"#\":\n",
    "            assert os.path.exists(args.model_path), \"[x] Model path is invalid: %s\" % self.args.model_path\n",
    "            self.load_model(args.model_path)\n",
    "\n",
    "    def set_log_path(self, timestamp):\n",
    "        log_path = self.log_root\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        if self.args.debug:\n",
    "            log_path += \"/%s_%s_debug/\" % (self.args.model, timestamp)\n",
    "            if not os.path.exists(log_path):\n",
    "                os.mkdir(log_path)\n",
    "            return log_path\n",
    "\n",
    "        log_path += \"/%s/\" % self.args.dataset\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        log_path += \"/%s/\" % self.args.application\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        log_path += \"/%s_%s/\" % (self.args.model, self.train_mode)\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        log_path += \"/%s_%s/\" % (self.args.model, timestamp)\n",
    "        if self.args.mode == \"eval\":\n",
    "            log_path = log_path[:-1] + \"_eval\"\n",
    "        if self.args.random:\n",
    "            log_path = log_path[:-1] + \"_random\"\n",
    "        log_path = log_path + \"/\"\n",
    "\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "        return log_path\n",
    "\n",
    "    def save_results(self, epoch, i_fold, results):\n",
    "        logging.info(\"[*] Saving files...\")\n",
    "        state = {\n",
    "            'args': self.args,\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        save_file = os.path.join(self.log_path, 'ckpt_{i}.pth'.format(i=i_fold))\n",
    "        torch.save(state, save_file)\n",
    "        np.save(os.path.join(self.log_path, \"best_valid_{i}\".format(i=i_fold)), results)\n",
    "        self.recorders.save(os.path.join(self.log_path, \"recorders_{i}.npz\".format(i=i_fold)))\n",
    "        self.recorders.record_to_csv(self.log_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location='cpu')\n",
    "        state_dict = ckpt['model']\n",
    "        model_dict = self.model.state_dict()\n",
    "        # print(state_dict, model_dict)\n",
    "        new_state_dict = {}\n",
    "        skipcount, loadedcount = 0, 0\n",
    "        for k, v in state_dict.items():\n",
    "            # print(k,v.shape, v[0])\n",
    "            k2 = k.replace(\"module.\", \"\")\n",
    "            if k in model_dict.keys():\n",
    "                new_state_dict[k] = v\n",
    "                loadedcount += 1\n",
    "            elif k2 in model_dict.keys():\n",
    "                new_state_dict[k2] = v\n",
    "                loadedcount += 1\n",
    "            else:\n",
    "                logging.info(\"skiped: %s\"%k)\n",
    "                skipcount += 1\n",
    "        model_dict.update(new_state_dict)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        logging.info(\"[*] Model loaded!\")\n",
    "        logging.info(\"[*] skipped: %d  loaded: %d\" % (skipcount, loadedcount))\n",
    "\n",
    "    def eval_model(self, model_path):\n",
    "        logging.info(\"=============== eval ===============\")\n",
    "        self.load_model(model_path)\n",
    "        save_flag, results = self.validate()\n",
    "        logging.info(self.recorders.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f0cad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:10:38.491003Z",
     "start_time": "2023-07-18T07:10:38.468307Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(active='relu', application='inhos_mortality', batch_size=128, clip_max=3.0, clip_min=-3.0, compress_dim=24, cosine=True, criterion='bce', data_clip=False, data_clip_max=inf, data_clip_min=-inf, dataset='MIMIC3', dataset_mode='regular', debug=False, embed_dim=24, epochs=200, ffill=True, ffill_steps=48, fix=False, folds=[3], fusion_dim=32, gpu='0,1,2', hidden_dim=32, inter_type='mul', k=7, lr=0.001, lr_decay_epochs='150,350,500', lr_decay_rate=0.1, max_cohort_size=8000, max_timesteps=48, min_freq=10, min_sample_freq=5, mode='train', model='CohortNet', model_path='#', momentum=0.9, opt='adam', patience=10, print_freq=20, random=True, standardization=True, topn=2, warm=True, weight_decay=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from argument import base_train_args, regular_dataset, CohortNet_parse_args\n",
    "import argparse\n",
    "base_parser = argparse.ArgumentParser(description=\"ECHO Framework.\",add_help=False, \n",
    "                                      parents=[base_train_args(), regular_dataset(), CohortNet_parse_args()])\n",
    "args = base_parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737f4c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T08:34:06.844218Z",
     "start_time": "2023-07-18T07:10:54.896287Z"
    },
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18-23 07:10:================== Start 20230718071054 ==================\n",
      "07-18-23 07:10:[*]random seed: 9093840\n",
      "07-18-23 07:10:Timestamp: 20230718071054\n",
      "07-18-23 07:10:Arguments\n",
      "07-18-23 07:10:active = relu\n",
      "07-18-23 07:10:application = inhos_mortality\n",
      "07-18-23 07:10:batch_size = 128\n",
      "07-18-23 07:10:clip_max = 3.0\n",
      "07-18-23 07:10:clip_min = -3.0\n",
      "07-18-23 07:10:compress_dim = 24\n",
      "07-18-23 07:10:cosine = True\n",
      "07-18-23 07:10:criterion = bce\n",
      "07-18-23 07:10:data_clip = False\n",
      "07-18-23 07:10:data_clip_max = inf\n",
      "07-18-23 07:10:data_clip_min = -inf\n",
      "07-18-23 07:10:dataset = MIMIC3\n",
      "07-18-23 07:10:dataset_mode = regular\n",
      "07-18-23 07:10:debug = False\n",
      "07-18-23 07:10:embed_dim = 24\n",
      "07-18-23 07:10:epochs = 200\n",
      "07-18-23 07:10:ffill = True\n",
      "07-18-23 07:10:ffill_steps = 48\n",
      "07-18-23 07:10:fix = False\n",
      "07-18-23 07:10:folds = [3]\n",
      "07-18-23 07:10:fusion_dim = 32\n",
      "07-18-23 07:10:gpu = 3,4,5\n",
      "07-18-23 07:10:hidden_dim = 32\n",
      "07-18-23 07:10:inter_type = mul\n",
      "07-18-23 07:10:k = 7\n",
      "07-18-23 07:10:lr = 0.001\n",
      "07-18-23 07:10:lr_decay_epochs = 150,350,500\n",
      "07-18-23 07:10:lr_decay_rate = 0.1\n",
      "07-18-23 07:10:max_cohort_size = 8000\n",
      "07-18-23 07:10:max_timesteps = 48\n",
      "07-18-23 07:10:min_freq = 10\n",
      "07-18-23 07:10:min_sample_freq = 5\n",
      "07-18-23 07:10:mode = train\n",
      "07-18-23 07:10:model = CohortNet\n",
      "07-18-23 07:10:model_path = #\n",
      "07-18-23 07:10:momentum = 0.9\n",
      "07-18-23 07:10:opt = adam\n",
      "07-18-23 07:10:patience = 10\n",
      "07-18-23 07:10:print_freq = 20\n",
      "07-18-23 07:10:random = True\n",
      "07-18-23 07:10:standardization = True\n",
      "07-18-23 07:10:topn = 2\n",
      "07-18-23 07:10:warm = True\n",
      "07-18-23 07:10:warm_epochs = 10\n",
      "07-18-23 07:10:warmup_from = 5e-05\n",
      "07-18-23 07:10:warmup_to = 0.0009928503261272714\n",
      "07-18-23 07:10:weight_decay = 0\n",
      "07-18-23 07:10:============= 3-th fold =============\n",
      "07-18-23 07:10:[*]loading the MIMIC3 dataset: train.\n",
      "07-18-23 07:10:[*] train: ['85929_episode1.npz' '90115_episode1.npz' '98016_episode1.npz'\n",
      " '45395_episode2.npz' '12250_episode1.npz']\n",
      "100%|██████████| 16911/16911 [00:56<00:00, 299.07it/s]\n",
      "07-18-23 07:11:[*]loading the MIMIC3 dataset: valid.\n",
      "07-18-23 07:11:[*] valid: ['27309_episode1.npz' '88214_episode1.npz' '89562_episode1.npz'\n",
      " '28578_episode1.npz' '47918_episode1.npz']\n",
      "100%|██████████| 2114/2114 [00:06<00:00, 302.42it/s]\n",
      "07-18-23 07:11:[*]loading the MIMIC3 dataset: test.\n",
      "07-18-23 07:11:[*] test: ['27586_episode1.npz' '43472_episode2.npz' '16776_episode1.npz'\n",
      " '5589_episode1.npz' '11056_episode1.npz']\n",
      "100%|██████████| 2114/2114 [00:07<00:00, 301.60it/s]\n",
      "07-18-23 07:12:[*] optimizer: Adam, lr: 0.001000, weight decay: 0.000000\n",
      "07-18-23 07:12:DataParallel(\n",
      "  (module): CohortNet(\n",
      "    (MFLM): MultiChannelFeatureLearningModule(\n",
      "      (biEmbedding): BiEmbedding()\n",
      "      (featureTrend): FeatureTrendLearning(\n",
      "        (embedRnns): ModuleList(\n",
      "          (0): GRU(24, 24, batch_first=True)\n",
      "          (1): GRU(24, 24, batch_first=True)\n",
      "          (2): GRU(24, 24, batch_first=True)\n",
      "          (3): GRU(24, 24, batch_first=True)\n",
      "          (4): GRU(24, 24, batch_first=True)\n",
      "          (5): GRU(24, 24, batch_first=True)\n",
      "          (6): GRU(24, 24, batch_first=True)\n",
      "          (7): GRU(24, 24, batch_first=True)\n",
      "          (8): GRU(24, 24, batch_first=True)\n",
      "          (9): GRU(24, 24, batch_first=True)\n",
      "          (10): GRU(24, 24, batch_first=True)\n",
      "          (11): GRU(24, 24, batch_first=True)\n",
      "          (12): GRU(24, 24, batch_first=True)\n",
      "          (13): GRU(24, 24, batch_first=True)\n",
      "          (14): GRU(24, 24, batch_first=True)\n",
      "          (15): GRU(24, 24, batch_first=True)\n",
      "          (16): GRU(24, 24, batch_first=True)\n",
      "          (17): GRU(24, 24, batch_first=True)\n",
      "          (18): GRU(24, 24, batch_first=True)\n",
      "          (19): GRU(24, 24, batch_first=True)\n",
      "          (20): GRU(24, 24, batch_first=True)\n",
      "          (21): GRU(24, 24, batch_first=True)\n",
      "          (22): GRU(24, 24, batch_first=True)\n",
      "          (23): GRU(24, 24, batch_first=True)\n",
      "          (24): GRU(24, 24, batch_first=True)\n",
      "          (25): GRU(24, 24, batch_first=True)\n",
      "          (26): GRU(24, 24, batch_first=True)\n",
      "          (27): GRU(24, 24, batch_first=True)\n",
      "          (28): GRU(24, 24, batch_first=True)\n",
      "          (29): GRU(24, 24, batch_first=True)\n",
      "          (30): GRU(24, 24, batch_first=True)\n",
      "          (31): GRU(24, 24, batch_first=True)\n",
      "          (32): GRU(24, 24, batch_first=True)\n",
      "          (33): GRU(24, 24, batch_first=True)\n",
      "          (34): GRU(24, 24, batch_first=True)\n",
      "          (35): GRU(24, 24, batch_first=True)\n",
      "          (36): GRU(24, 24, batch_first=True)\n",
      "          (37): GRU(24, 24, batch_first=True)\n",
      "          (38): GRU(24, 24, batch_first=True)\n",
      "          (39): GRU(24, 24, batch_first=True)\n",
      "          (40): GRU(24, 24, batch_first=True)\n",
      "          (41): GRU(24, 24, batch_first=True)\n",
      "          (42): GRU(24, 24, batch_first=True)\n",
      "          (43): GRU(24, 24, batch_first=True)\n",
      "          (44): GRU(24, 24, batch_first=True)\n",
      "          (45): GRU(24, 24, batch_first=True)\n",
      "          (46): GRU(24, 24, batch_first=True)\n",
      "          (47): GRU(24, 24, batch_first=True)\n",
      "          (48): GRU(24, 24, batch_first=True)\n",
      "          (49): GRU(24, 24, batch_first=True)\n",
      "          (50): GRU(24, 24, batch_first=True)\n",
      "          (51): GRU(24, 24, batch_first=True)\n",
      "          (52): GRU(24, 24, batch_first=True)\n",
      "          (53): GRU(24, 24, batch_first=True)\n",
      "          (54): GRU(24, 24, batch_first=True)\n",
      "          (55): GRU(24, 24, batch_first=True)\n",
      "          (56): GRU(24, 24, batch_first=True)\n",
      "          (57): GRU(24, 24, batch_first=True)\n",
      "          (58): GRU(24, 24, batch_first=True)\n",
      "          (59): GRU(24, 24, batch_first=True)\n",
      "          (60): GRU(24, 24, batch_first=True)\n",
      "          (61): GRU(24, 24, batch_first=True)\n",
      "          (62): GRU(24, 24, batch_first=True)\n",
      "        )\n",
      "      )\n",
      "      (featureInteractionModule): FeatureInteractionLearning(\n",
      "        (a_ff): ModuleList(\n",
      "          (0): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (1): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (2): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (3): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (4): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (5): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (6): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (7): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (8): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (9): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (10): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (11): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (12): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (13): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (14): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (15): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (16): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (17): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (18): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (19): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (20): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (21): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (22): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (23): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (24): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (25): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (26): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (27): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (28): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (29): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (30): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (31): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (32): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (33): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (34): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (35): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (36): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (37): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (38): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (39): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (40): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (41): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (42): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (43): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (44): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (45): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (46): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (47): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (48): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (49): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (50): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (51): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (52): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (53): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (54): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (55): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (56): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (57): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (58): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (59): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (60): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (61): Linear(in_features=24, out_features=24, bias=True)\n",
      "          (62): Linear(in_features=24, out_features=24, bias=True)\n",
      "        )\n",
      "        (a_ff2): ModuleList(\n",
      "          (0): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (1): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (2): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (3): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (4): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (5): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (6): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (7): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (8): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (9): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (10): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (11): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (12): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (13): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (14): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (15): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (16): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (17): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (18): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (19): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (20): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (21): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (22): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (23): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (24): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (25): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (26): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (27): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (28): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (29): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (30): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (31): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (32): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (33): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (34): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (35): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (36): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (37): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (38): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (39): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (40): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (41): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (42): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (43): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (44): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (45): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (46): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (47): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (48): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (49): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (50): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (51): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (52): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (53): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (54): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (55): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (56): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (57): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (58): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (59): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (60): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (61): Linear(in_features=24, out_features=1, bias=False)\n",
      "          (62): Linear(in_features=24, out_features=1, bias=False)\n",
      "        )\n",
      "        (active): ReLU(inplace=True)\n",
      "        (softmax): Softmax(dim=2)\n",
      "      )\n",
      "      (featureFusionModule): FeatureFusion(\n",
      "        (active): ReLU()\n",
      "        (compressor): Linear(in_features=72, out_features=32, bias=True)\n",
      "      )\n",
      "      (rnns): ModuleList(\n",
      "        (0): GRU(32, 32, batch_first=True)\n",
      "        (1): GRU(32, 32, batch_first=True)\n",
      "        (2): GRU(32, 32, batch_first=True)\n",
      "        (3): GRU(32, 32, batch_first=True)\n",
      "        (4): GRU(32, 32, batch_first=True)\n",
      "        (5): GRU(32, 32, batch_first=True)\n",
      "        (6): GRU(32, 32, batch_first=True)\n",
      "        (7): GRU(32, 32, batch_first=True)\n",
      "        (8): GRU(32, 32, batch_first=True)\n",
      "        (9): GRU(32, 32, batch_first=True)\n",
      "        (10): GRU(32, 32, batch_first=True)\n",
      "        (11): GRU(32, 32, batch_first=True)\n",
      "        (12): GRU(32, 32, batch_first=True)\n",
      "        (13): GRU(32, 32, batch_first=True)\n",
      "        (14): GRU(32, 32, batch_first=True)\n",
      "        (15): GRU(32, 32, batch_first=True)\n",
      "        (16): GRU(32, 32, batch_first=True)\n",
      "        (17): GRU(32, 32, batch_first=True)\n",
      "        (18): GRU(32, 32, batch_first=True)\n",
      "        (19): GRU(32, 32, batch_first=True)\n",
      "        (20): GRU(32, 32, batch_first=True)\n",
      "        (21): GRU(32, 32, batch_first=True)\n",
      "        (22): GRU(32, 32, batch_first=True)\n",
      "        (23): GRU(32, 32, batch_first=True)\n",
      "        (24): GRU(32, 32, batch_first=True)\n",
      "        (25): GRU(32, 32, batch_first=True)\n",
      "        (26): GRU(32, 32, batch_first=True)\n",
      "        (27): GRU(32, 32, batch_first=True)\n",
      "        (28): GRU(32, 32, batch_first=True)\n",
      "        (29): GRU(32, 32, batch_first=True)\n",
      "        (30): GRU(32, 32, batch_first=True)\n",
      "        (31): GRU(32, 32, batch_first=True)\n",
      "        (32): GRU(32, 32, batch_first=True)\n",
      "        (33): GRU(32, 32, batch_first=True)\n",
      "        (34): GRU(32, 32, batch_first=True)\n",
      "        (35): GRU(32, 32, batch_first=True)\n",
      "        (36): GRU(32, 32, batch_first=True)\n",
      "        (37): GRU(32, 32, batch_first=True)\n",
      "        (38): GRU(32, 32, batch_first=True)\n",
      "        (39): GRU(32, 32, batch_first=True)\n",
      "        (40): GRU(32, 32, batch_first=True)\n",
      "        (41): GRU(32, 32, batch_first=True)\n",
      "        (42): GRU(32, 32, batch_first=True)\n",
      "        (43): GRU(32, 32, batch_first=True)\n",
      "        (44): GRU(32, 32, batch_first=True)\n",
      "        (45): GRU(32, 32, batch_first=True)\n",
      "        (46): GRU(32, 32, batch_first=True)\n",
      "        (47): GRU(32, 32, batch_first=True)\n",
      "        (48): GRU(32, 32, batch_first=True)\n",
      "        (49): GRU(32, 32, batch_first=True)\n",
      "        (50): GRU(32, 32, batch_first=True)\n",
      "        (51): GRU(32, 32, batch_first=True)\n",
      "        (52): GRU(32, 32, batch_first=True)\n",
      "        (53): GRU(32, 32, batch_first=True)\n",
      "        (54): GRU(32, 32, batch_first=True)\n",
      "        (55): GRU(32, 32, batch_first=True)\n",
      "        (56): GRU(32, 32, batch_first=True)\n",
      "        (57): GRU(32, 32, batch_first=True)\n",
      "        (58): GRU(32, 32, batch_first=True)\n",
      "        (59): GRU(32, 32, batch_first=True)\n",
      "        (60): GRU(32, 32, batch_first=True)\n",
      "        (61): GRU(32, 32, batch_first=True)\n",
      "        (62): GRU(32, 32, batch_first=True)\n",
      "      )\n",
      "      (active): ReLU()\n",
      "      (linears): ModuleList(\n",
      "        (0): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (1): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (2): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (3): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (4): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (5): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (6): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (7): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (8): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (9): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (10): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (11): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (12): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (13): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (14): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (15): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (16): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (17): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (18): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (19): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (20): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (21): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (22): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (23): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (24): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (25): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (26): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (27): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (28): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (29): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (30): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (31): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (32): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (33): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (34): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (35): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (36): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (37): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (38): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (39): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (40): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (41): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (42): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (43): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (44): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (45): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (46): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (47): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (48): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (49): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (50): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (51): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (52): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (53): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (54): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (55): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (56): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (57): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (58): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (59): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (60): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (61): Linear(in_features=32, out_features=24, bias=True)\n",
      "        (62): Linear(in_features=32, out_features=24, bias=True)\n",
      "      )\n",
      "      (prediction): Linear(in_features=1512, out_features=1, bias=True)\n",
      "    )\n",
      "    (CEM): CohortExploitationModule(\n",
      "      (active): ReLU()\n",
      "      (cohort_attention): ModuleList(\n",
      "        (0): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (1): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (2): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (4): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (5): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (6): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (7): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (8): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (9): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (10): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (11): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (12): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (13): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (14): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (15): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (16): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (17): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (18): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (19): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (20): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (21): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (22): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (23): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (24): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (25): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (26): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (27): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (28): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (29): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (30): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (31): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (32): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (33): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (34): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (35): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (36): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (37): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (38): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (39): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (40): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (41): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (42): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (43): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (44): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (45): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (46): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (47): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (48): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (49): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (50): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (51): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (52): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (53): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (54): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (55): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (56): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (57): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (58): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (59): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (60): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (61): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (62): FinalAttentionQKV(\n",
      "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (W_k): Linear(in_features=33, out_features=32, bias=True)\n",
      "          (W_v): Linear(in_features=33, out_features=33, bias=True)\n",
      "          (tanh): Tanh()\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (compress): Linear(in_features=2016, out_features=32, bias=True)\n",
      "      (predictionCohort): Linear(in_features=2079, out_features=1, bias=False)\n",
      "    )\n",
      "    (activation): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18-23 07:12:Model param num: 995942  trainable: 995942\n",
      "07-18-23 07:12:Train: [1][0/133]\tBT avg 8.678\tloss avg 0.7005\n",
      "07-18-23 07:12:Train: [1][20/133]\tBT avg 0.984\tloss avg 0.6401\n",
      "07-18-23 07:12:Train: [1][40/133]\tBT avg 0.796\tloss avg 0.5842\n",
      "07-18-23 07:12:Train: [1][60/133]\tBT avg 0.730\tloss avg 0.5397\n",
      "07-18-23 07:13:Train: [1][80/133]\tBT avg 0.697\tloss avg 0.5081\n",
      "07-18-23 07:13:Train: [1][100/133]\tBT avg 0.678\tloss avg 0.4853\n",
      "07-18-23 07:13:Train: [1][120/133]\tBT avg 0.665\tloss avg 0.4705\n",
      "07-18-23 07:14:Epoch 1, lr 0.000144, train loss 0.4641, train time 87.90s, valid time 43.67s, total time 131.57s.\n",
      "07-18-23 07:14:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.3890   0.6539   0.2602   0.8677   0.0000   0.2987   \n",
      "valid 0.3896   0.6167   0.2451   0.8675   0.0000   0.3036   \n",
      "test  0.3884   0.6500   0.2578   0.8680   0.0000   0.3176   \n",
      "\n",
      "07-18-23 07:14:[*] Saving files...\n",
      "07-18-23 07:14:Train: [2][0/133]\tBT avg 0.578\tloss avg 0.3010\n",
      "07-18-23 07:14:Train: [2][20/133]\tBT avg 0.600\tloss avg 0.3783\n",
      "07-18-23 07:14:Train: [2][40/133]\tBT avg 0.598\tloss avg 0.3972\n",
      "07-18-23 07:14:Train: [2][60/133]\tBT avg 0.598\tloss avg 0.3916\n",
      "07-18-23 07:15:Train: [2][80/133]\tBT avg 0.597\tloss avg 0.3918\n",
      "07-18-23 07:15:Train: [2][100/133]\tBT avg 0.599\tloss avg 0.3878\n",
      "07-18-23 07:15:Train: [2][120/133]\tBT avg 0.600\tloss avg 0.3882\n",
      "07-18-23 07:16:Epoch 2, lr 0.000239, train loss 0.3847, train time 80.40s, valid time 43.49s, total time 123.89s.\n",
      "07-18-23 07:16:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.3780   0.7005   0.3010   0.8677   0.0000   0.3127   \n",
      "valid 0.3812   0.6576   0.2695   0.8675   0.0000   0.2801   \n",
      "test  0.3779   0.6891   0.2914   0.8680   0.0000   0.3125   \n",
      "\n",
      "07-18-23 07:16:[*] Saving files...\n",
      "07-18-23 07:16:Train: [3][0/133]\tBT avg 0.580\tloss avg 0.3682\n",
      "07-18-23 07:16:Train: [3][20/133]\tBT avg 0.603\tloss avg 0.3995\n",
      "07-18-23 07:16:Train: [3][40/133]\tBT avg 0.605\tloss avg 0.3807\n",
      "07-18-23 07:17:Train: [3][60/133]\tBT avg 0.606\tloss avg 0.3740\n",
      "07-18-23 07:17:Train: [3][80/133]\tBT avg 0.606\tloss avg 0.3654\n",
      "07-18-23 07:17:Train: [3][100/133]\tBT avg 0.606\tloss avg 0.3584\n",
      "07-18-23 07:17:Train: [3][120/133]\tBT avg 0.606\tloss avg 0.3542\n",
      "07-18-23 07:18:Epoch 3, lr 0.000333, train loss 0.3516, train time 80.49s, valid time 43.39s, total time 123.87s.\n",
      "07-18-23 07:18:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.3256   0.7969   0.4018   0.8724   0.1326   0.4174   \n",
      "valid 0.3435   0.7564   0.3433   0.8718   0.1173   0.3587   \n",
      "test  0.3294   0.7835   0.3784   0.8685   0.1146   0.4373   \n",
      "\n",
      "07-18-23 07:18:[*] Saving files...\n",
      "07-18-23 07:18:Train: [4][0/133]\tBT avg 0.584\tloss avg 0.3929\n",
      "07-18-23 07:18:Train: [4][20/133]\tBT avg 0.603\tloss avg 0.3253\n",
      "07-18-23 07:18:Train: [4][40/133]\tBT avg 0.603\tloss avg 0.3367\n",
      "07-18-23 07:19:Train: [4][60/133]\tBT avg 0.604\tloss avg 0.3228\n",
      "07-18-23 07:19:Train: [4][80/133]\tBT avg 0.604\tloss avg 0.3206\n",
      "07-18-23 07:19:Train: [4][100/133]\tBT avg 0.605\tloss avg 0.3199\n",
      "07-18-23 07:19:Train: [4][120/133]\tBT avg 0.605\tloss avg 0.3179\n",
      "07-18-23 07:20:Epoch 4, lr 0.000427, train loss 0.3163, train time 80.63s, valid time 43.42s, total time 124.05s.\n",
      "07-18-23 07:20:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.3052   0.8213   0.4650   0.8791   0.2912   0.4634   \n",
      "valid 0.3229   0.7929   0.4016   0.8751   0.2326   0.4250   \n",
      "test  0.3078   0.8135   0.4511   0.8784   0.2920   0.4737   \n",
      "\n",
      "07-18-23 07:20:[*] Saving files...\n",
      "07-18-23 07:20:Train: [5][0/133]\tBT avg 0.594\tloss avg 0.2160\n",
      "07-18-23 07:20:Train: [5][20/133]\tBT avg 0.602\tloss avg 0.3262\n",
      "07-18-23 07:21:Train: [5][40/133]\tBT avg 0.604\tloss avg 0.3072\n",
      "07-18-23 07:21:Train: [5][60/133]\tBT avg 0.605\tloss avg 0.3102\n",
      "07-18-23 07:21:Train: [5][80/133]\tBT avg 0.606\tloss avg 0.3111\n",
      "07-18-23 07:21:Train: [5][100/133]\tBT avg 0.605\tloss avg 0.3086\n",
      "07-18-23 07:21:Train: [5][120/133]\tBT avg 0.605\tloss avg 0.3054\n",
      "07-18-23 07:22:Epoch 5, lr 0.000521, train loss 0.3023, train time 80.65s, valid time 43.61s, total time 124.26s.\n",
      "07-18-23 07:22:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2929   0.8415   0.4973   0.8826   0.3350   0.4873   \n",
      "valid 0.3128   0.8156   0.4264   0.8761   0.2880   0.4214   \n",
      "test  0.2935   0.8381   0.4979   0.8817   0.3207   0.5018   \n",
      "\n",
      "07-18-23 07:22:[*] Saving files...\n",
      "07-18-23 07:22:Train: [6][0/133]\tBT avg 0.635\tloss avg 0.2740\n",
      "07-18-23 07:22:Train: [6][20/133]\tBT avg 0.603\tloss avg 0.3145\n",
      "07-18-23 07:23:Train: [6][40/133]\tBT avg 0.602\tloss avg 0.2933\n",
      "07-18-23 07:23:Train: [6][60/133]\tBT avg 0.603\tloss avg 0.2958\n",
      "07-18-23 07:23:Train: [6][80/133]\tBT avg 0.604\tloss avg 0.2958\n",
      "07-18-23 07:23:Train: [6][100/133]\tBT avg 0.604\tloss avg 0.2947\n",
      "07-18-23 07:23:Train: [6][120/133]\tBT avg 0.604\tloss avg 0.2933\n",
      "07-18-23 07:24:Epoch 6, lr 0.000616, train loss 0.2954, train time 80.54s, valid time 43.80s, total time 124.33s.\n",
      "07-18-23 07:24:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2932   0.8452   0.5037   0.8824   0.3292   0.4897   \n",
      "valid 0.3152   0.8209   0.4376   0.8765   0.2770   0.4393   \n",
      "test  0.2936   0.8392   0.5052   0.8794   0.3089   0.4800   \n",
      "\n",
      "07-18-23 07:24:Train: [7][0/133]\tBT avg 0.594\tloss avg 0.3096\n",
      "07-18-23 07:24:Train: [7][20/133]\tBT avg 0.603\tloss avg 0.3018\n",
      "07-18-23 07:25:Train: [7][40/133]\tBT avg 0.603\tloss avg 0.2970\n",
      "07-18-23 07:25:Train: [7][60/133]\tBT avg 0.601\tloss avg 0.2941\n",
      "07-18-23 07:25:Train: [7][80/133]\tBT avg 0.603\tloss avg 0.2942\n",
      "07-18-23 07:25:Train: [7][100/133]\tBT avg 0.602\tloss avg 0.2944\n",
      "07-18-23 07:25:Train: [7][120/133]\tBT avg 0.602\tloss avg 0.2928\n",
      "07-18-23 07:26:Epoch 7, lr 0.000710, train loss 0.2937, train time 80.30s, valid time 43.72s, total time 124.02s.\n",
      "07-18-23 07:26:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2875   0.8522   0.5172   0.8856   0.4175   0.4929   \n",
      "valid 0.3062   0.8272   0.4525   0.8728   0.3258   0.4500   \n",
      "test  0.2922   0.8436   0.5115   0.8803   0.4019   0.4875   \n",
      "\n",
      "07-18-23 07:26:[*] Saving files...\n",
      "07-18-23 07:26:Train: [8][0/133]\tBT avg 0.586\tloss avg 0.3887\n",
      "07-18-23 07:27:Train: [8][20/133]\tBT avg 0.604\tloss avg 0.2931\n",
      "07-18-23 07:27:Train: [8][40/133]\tBT avg 0.601\tloss avg 0.2921\n",
      "07-18-23 07:27:Train: [8][60/133]\tBT avg 0.600\tloss avg 0.2878\n",
      "07-18-23 07:27:Train: [8][80/133]\tBT avg 0.600\tloss avg 0.2891\n",
      "07-18-23 07:27:Train: [8][100/133]\tBT avg 0.601\tloss avg 0.2911\n",
      "07-18-23 07:28:Train: [8][120/133]\tBT avg 0.602\tloss avg 0.2874\n",
      "07-18-23 07:28:Epoch 8, lr 0.000804, train loss 0.2883, train time 80.28s, valid time 43.39s, total time 123.66s.\n",
      "07-18-23 07:28:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2843   0.8526   0.5336   0.8861   0.3448   0.5116   \n",
      "valid 0.3010   0.8323   0.4766   0.8784   0.2841   0.4754   \n",
      "test  0.2881   0.8447   0.5224   0.8879   0.3542   0.4875   \n",
      "\n",
      "07-18-23 07:28:[*] Saving files...\n",
      "07-18-23 07:28:Train: [9][0/133]\tBT avg 0.596\tloss avg 0.2683\n",
      "07-18-23 07:29:Train: [9][20/133]\tBT avg 0.603\tloss avg 0.2858\n",
      "07-18-23 07:29:Train: [9][40/133]\tBT avg 0.604\tloss avg 0.2908\n",
      "07-18-23 07:29:Train: [9][60/133]\tBT avg 0.603\tloss avg 0.2897\n",
      "07-18-23 07:29:Train: [9][80/133]\tBT avg 0.603\tloss avg 0.2878\n",
      "07-18-23 07:29:Train: [9][100/133]\tBT avg 0.602\tloss avg 0.2860\n",
      "07-18-23 07:30:Train: [9][120/133]\tBT avg 0.602\tloss avg 0.2861\n",
      "07-18-23 07:30:Epoch 9, lr 0.000899, train loss 0.2876, train time 80.36s, valid time 43.66s, total time 124.02s.\n",
      "07-18-23 07:30:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2825   0.8571   0.5314   0.8861   0.4036   0.5027   \n",
      "valid 0.2996   0.8344   0.4739   0.8780   0.3518   0.4662   \n",
      "test  0.2853   0.8506   0.5322   0.8893   0.4265   0.5090   \n",
      "\n",
      "07-18-23 07:30:[*] Saving files...\n",
      "07-18-23 07:30:Train: [10][0/133]\tBT avg 0.599\tloss avg 0.2715\n",
      "07-18-23 07:31:Train: [10][20/133]\tBT avg 0.606\tloss avg 0.2873\n",
      "07-18-23 07:31:Train: [10][40/133]\tBT avg 0.606\tloss avg 0.2888\n",
      "07-18-23 07:31:Train: [10][60/133]\tBT avg 0.605\tloss avg 0.2970\n",
      "07-18-23 07:31:Train: [10][80/133]\tBT avg 0.603\tloss avg 0.2934\n",
      "07-18-23 07:31:Train: [10][100/133]\tBT avg 0.603\tloss avg 0.2933\n",
      "07-18-23 07:32:Train: [10][120/133]\tBT avg 0.602\tloss avg 0.2900\n",
      "07-18-23 07:33:Epoch 10, lr 0.000993, train loss 0.2903, train time 80.28s, valid time 43.81s, total time 124.10s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18-23 07:33:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2816   0.8570   0.5404   0.8879   0.4428   0.5094   \n",
      "valid 0.2988   0.8378   0.4809   0.8732   0.3558   0.4737   \n",
      "test  0.2850   0.8521   0.5344   0.8855   0.4292   0.5071   \n",
      "\n",
      "07-18-23 07:33:[*] Saving files...\n",
      "07-18-23 07:33:Train: [11][0/133]\tBT avg 0.581\tloss avg 0.2481\n",
      "07-18-23 07:33:Train: [11][20/133]\tBT avg 0.603\tloss avg 0.2731\n",
      "07-18-23 07:33:Train: [11][40/133]\tBT avg 0.604\tloss avg 0.2787\n",
      "07-18-23 07:33:Train: [11][60/133]\tBT avg 0.603\tloss avg 0.2843\n",
      "07-18-23 07:33:Train: [11][80/133]\tBT avg 0.604\tloss avg 0.2827\n",
      "07-18-23 07:34:Train: [11][100/133]\tBT avg 0.603\tloss avg 0.2830\n",
      "07-18-23 07:34:Train: [11][120/133]\tBT avg 0.602\tloss avg 0.2843\n",
      "07-18-23 07:35:Epoch 11, lr 0.001000, train loss 0.2846, train time 80.30s, valid time 43.55s, total time 123.86s.\n",
      "07-18-23 07:35:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2891   0.8601   0.5490   0.8856   0.3027   0.5226   \n",
      "valid 0.3067   0.8434   0.4884   0.8780   0.2321   0.4718   \n",
      "test  0.2898   0.8548   0.5428   0.8879   0.3286   0.5089   \n",
      "\n",
      "07-18-23 07:35:Train: [12][0/133]\tBT avg 0.578\tloss avg 0.2155\n",
      "07-18-23 07:35:Train: [12][20/133]\tBT avg 0.597\tloss avg 0.2866\n",
      "07-18-23 07:35:Train: [12][40/133]\tBT avg 0.603\tloss avg 0.2880\n",
      "07-18-23 07:35:Train: [12][60/133]\tBT avg 0.603\tloss avg 0.2875\n",
      "07-18-23 07:35:Train: [12][80/133]\tBT avg 0.603\tloss avg 0.2889\n",
      "07-18-23 07:36:Train: [12][100/133]\tBT avg 0.603\tloss avg 0.2859\n",
      "07-18-23 07:36:Train: [12][120/133]\tBT avg 0.602\tloss avg 0.2809\n",
      "07-18-23 07:37:Epoch 12, lr 0.001000, train loss 0.2829, train time 80.27s, valid time 43.62s, total time 123.90s.\n",
      "07-18-23 07:37:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.3056   0.8572   0.5504   0.8830   0.2426   0.5259   \n",
      "valid 0.3246   0.8377   0.4889   0.8808   0.2125   0.4840   \n",
      "test  0.3062   0.8476   0.5477   0.8827   0.2439   0.5000   \n",
      "\n",
      "07-18-23 07:37:Train: [13][0/133]\tBT avg 0.586\tloss avg 0.2832\n",
      "07-18-23 07:37:Train: [13][20/133]\tBT avg 0.608\tloss avg 0.2956\n",
      "07-18-23 07:37:Train: [13][40/133]\tBT avg 0.607\tloss avg 0.2906\n",
      "07-18-23 07:37:Train: [13][60/133]\tBT avg 0.605\tloss avg 0.2885\n",
      "07-18-23 07:37:Train: [13][80/133]\tBT avg 0.603\tloss avg 0.2898\n",
      "07-18-23 07:38:Train: [13][100/133]\tBT avg 0.603\tloss avg 0.2857\n",
      "07-18-23 07:38:Train: [13][120/133]\tBT avg 0.603\tloss avg 0.2852\n",
      "07-18-23 07:39:Epoch 13, lr 0.000999, train loss 0.2827, train time 80.36s, valid time 43.84s, total time 124.20s.\n",
      "07-18-23 07:39:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2777   0.8610   0.5603   0.8896   0.3737   0.5343   \n",
      "valid 0.2943   0.8467   0.4996   0.8798   0.2983   0.4702   \n",
      "test  0.2824   0.8532   0.5438   0.8884   0.3757   0.5090   \n",
      "\n",
      "07-18-23 07:39:[*] Saving files...\n",
      "07-18-23 07:39:Train: [14][0/133]\tBT avg 0.588\tloss avg 0.3034\n",
      "07-18-23 07:39:Train: [14][20/133]\tBT avg 0.598\tloss avg 0.2583\n",
      "07-18-23 07:39:Train: [14][40/133]\tBT avg 0.599\tloss avg 0.2712\n",
      "07-18-23 07:39:Train: [14][60/133]\tBT avg 0.600\tloss avg 0.2729\n",
      "07-18-23 07:40:Train: [14][80/133]\tBT avg 0.600\tloss avg 0.2740\n",
      "07-18-23 07:40:Train: [14][100/133]\tBT avg 0.600\tloss avg 0.2750\n",
      "07-18-23 07:40:Train: [14][120/133]\tBT avg 0.600\tloss avg 0.2788\n",
      "07-18-23 07:41:Epoch 14, lr 0.000999, train loss 0.2800, train time 79.93s, valid time 43.70s, total time 123.63s.\n",
      "07-18-23 07:41:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2738   0.8650   0.5638   0.8903   0.4308   0.5243   \n",
      "valid 0.2901   0.8501   0.4964   0.8798   0.3713   0.4683   \n",
      "test  0.2778   0.8576   0.5575   0.8912   0.4363   0.5125   \n",
      "\n",
      "07-18-23 07:41:[*] Saving files...\n",
      "07-18-23 07:41:Train: [15][0/133]\tBT avg 0.590\tloss avg 0.2934\n",
      "07-18-23 07:41:Train: [15][20/133]\tBT avg 0.603\tloss avg 0.2649\n",
      "07-18-23 07:41:Train: [15][40/133]\tBT avg 0.602\tloss avg 0.2706\n",
      "07-18-23 07:41:Train: [15][60/133]\tBT avg 0.602\tloss avg 0.2737\n",
      "07-18-23 07:42:Train: [15][80/133]\tBT avg 0.601\tloss avg 0.2742\n",
      "07-18-23 07:42:Train: [15][100/133]\tBT avg 0.602\tloss avg 0.2760\n",
      "07-18-23 07:42:Train: [15][120/133]\tBT avg 0.601\tloss avg 0.2784\n",
      "07-18-23 07:43:Epoch 15, lr 0.000998, train loss 0.2795, train time 80.03s, valid time 43.89s, total time 123.92s.\n",
      "07-18-23 07:43:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2753   0.8659   0.5583   0.8889   0.4765   0.5232   \n",
      "valid 0.2948   0.8487   0.4862   0.8784   0.4037   0.4823   \n",
      "test  0.2830   0.8568   0.5431   0.8822   0.4527   0.5161   \n",
      "\n",
      "07-18-23 07:43:Train: [16][0/133]\tBT avg 0.632\tloss avg 0.2643\n",
      "07-18-23 07:43:Train: [16][20/133]\tBT avg 0.604\tloss avg 0.2854\n",
      "07-18-23 07:43:Train: [16][40/133]\tBT avg 0.604\tloss avg 0.2781\n",
      "07-18-23 07:43:Train: [16][60/133]\tBT avg 0.600\tloss avg 0.2799\n",
      "07-18-23 07:44:Train: [16][80/133]\tBT avg 0.602\tloss avg 0.2780\n",
      "07-18-23 07:44:Train: [16][100/133]\tBT avg 0.602\tloss avg 0.2771\n",
      "07-18-23 07:44:Train: [16][120/133]\tBT avg 0.601\tloss avg 0.2770\n",
      "07-18-23 07:45:Epoch 16, lr 0.000998, train loss 0.2786, train time 80.18s, valid time 43.31s, total time 123.49s.\n",
      "07-18-23 07:45:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2712   0.8684   0.5702   0.8900   0.3945   0.5373   \n",
      "valid 0.2859   0.8572   0.5080   0.8822   0.3360   0.4843   \n",
      "test  0.2772   0.8606   0.5502   0.8898   0.4010   0.5125   \n",
      "\n",
      "07-18-23 07:45:[*] Saving files...\n",
      "07-18-23 07:45:Train: [17][0/133]\tBT avg 0.588\tloss avg 0.3364\n",
      "07-18-23 07:45:Train: [17][20/133]\tBT avg 0.600\tloss avg 0.2815\n",
      "07-18-23 07:45:Train: [17][40/133]\tBT avg 0.599\tloss avg 0.2830\n",
      "07-18-23 07:46:Train: [17][60/133]\tBT avg 0.600\tloss avg 0.2882\n",
      "07-18-23 07:46:Train: [17][80/133]\tBT avg 0.601\tloss avg 0.2858\n",
      "07-18-23 07:46:Train: [17][100/133]\tBT avg 0.601\tloss avg 0.2828\n",
      "07-18-23 07:46:Train: [17][120/133]\tBT avg 0.601\tloss avg 0.2776\n",
      "07-18-23 07:47:Epoch 17, lr 0.000997, train loss 0.2797, train time 80.07s, valid time 43.53s, total time 123.60s.\n",
      "07-18-23 07:47:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2703   0.8703   0.5723   0.8905   0.4185   0.5324   \n",
      "valid 0.2902   0.8549   0.5061   0.8836   0.3594   0.4930   \n",
      "test  0.2753   0.8636   0.5576   0.8874   0.4138   0.5143   \n",
      "\n",
      "07-18-23 07:47:Train: [18][0/133]\tBT avg 0.642\tloss avg 0.3045\n",
      "07-18-23 07:47:Train: [18][20/133]\tBT avg 0.605\tloss avg 0.2860\n",
      "07-18-23 07:47:Train: [18][40/133]\tBT avg 0.606\tloss avg 0.2732\n",
      "07-18-23 07:48:Train: [18][60/133]\tBT avg 0.606\tloss avg 0.2758\n",
      "07-18-23 07:48:Train: [18][80/133]\tBT avg 0.605\tloss avg 0.2759\n",
      "07-18-23 07:48:Train: [18][100/133]\tBT avg 0.605\tloss avg 0.2741\n",
      "07-18-23 07:48:Train: [18][120/133]\tBT avg 0.604\tloss avg 0.2735\n",
      "07-18-23 07:49:Epoch 18, lr 0.000996, train loss 0.2752, train time 80.51s, valid time 43.87s, total time 124.38s.\n",
      "07-18-23 07:49:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2707   0.8716   0.5783   0.8913   0.3938   0.5355   \n",
      "valid 0.2904   0.8554   0.5069   0.8808   0.3226   0.4893   \n",
      "test  0.2772   0.8617   0.5571   0.8888   0.3733   0.5090   \n",
      "\n",
      "07-18-23 07:49:Train: [19][0/133]\tBT avg 0.635\tloss avg 0.1933\n",
      "07-18-23 07:49:Train: [19][20/133]\tBT avg 0.601\tloss avg 0.2663\n",
      "07-18-23 07:49:Train: [19][40/133]\tBT avg 0.602\tloss avg 0.2729\n",
      "07-18-23 07:50:Train: [19][60/133]\tBT avg 0.602\tloss avg 0.2704\n",
      "07-18-23 07:50:Train: [19][80/133]\tBT avg 0.601\tloss avg 0.2731\n",
      "07-18-23 07:50:Train: [19][100/133]\tBT avg 0.602\tloss avg 0.2750\n",
      "07-18-23 07:50:Train: [19][120/133]\tBT avg 0.601\tloss avg 0.2746\n",
      "07-18-23 07:51:Epoch 19, lr 0.000994, train loss 0.2728, train time 80.23s, valid time 42.96s, total time 123.19s.\n",
      "07-18-23 07:51:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2730   0.8728   0.5759   0.8892   0.5023   0.5395   \n",
      "valid 0.2883   0.8589   0.5133   0.8756   0.4220   0.4930   \n",
      "test  0.2860   0.8583   0.5462   0.8789   0.4711   0.5125   \n",
      "\n",
      "07-18-23 07:51:Train: [20][0/133]\tBT avg 0.614\tloss avg 0.2147\n",
      "07-18-23 07:51:Train: [20][20/133]\tBT avg 0.602\tloss avg 0.2678\n",
      "07-18-23 07:52:Train: [20][40/133]\tBT avg 0.604\tloss avg 0.2679\n",
      "07-18-23 07:52:Train: [20][60/133]\tBT avg 0.603\tloss avg 0.2720\n",
      "07-18-23 07:52:Train: [20][80/133]\tBT avg 0.604\tloss avg 0.2737\n",
      "07-18-23 07:52:Train: [20][100/133]\tBT avg 0.604\tloss avg 0.2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18-23 07:52:Train: [20][120/133]\tBT avg 0.604\tloss avg 0.2739\n",
      "07-18-23 07:53:Epoch 20, lr 0.000993, train loss 0.2731, train time 80.52s, valid time 43.31s, total time 123.83s.\n",
      "07-18-23 07:53:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2650   0.8755   0.5873   0.8931   0.4293   0.5460   \n",
      "valid 0.2828   0.8624   0.5145   0.8798   0.3420   0.4982   \n",
      "test  0.2751   0.8616   0.5572   0.8898   0.4190   0.4947   \n",
      "\n",
      "07-18-23 07:53:[*] Saving files...\n",
      "07-18-23 07:53:Train: [21][0/133]\tBT avg 0.577\tloss avg 0.3107\n",
      "07-18-23 07:53:Train: [21][20/133]\tBT avg 0.599\tloss avg 0.2653\n",
      "07-18-23 07:54:Train: [21][40/133]\tBT avg 0.601\tloss avg 0.2699\n",
      "07-18-23 07:54:Train: [21][60/133]\tBT avg 0.602\tloss avg 0.2708\n",
      "07-18-23 07:54:Train: [21][80/133]\tBT avg 0.601\tloss avg 0.2717\n",
      "07-18-23 07:54:Train: [21][100/133]\tBT avg 0.600\tloss avg 0.2703\n",
      "07-18-23 07:54:Train: [21][120/133]\tBT avg 0.600\tloss avg 0.2728\n",
      "07-18-23 07:55:Epoch 21, lr 0.000992, train loss 0.2700, train time 79.92s, valid time 43.42s, total time 123.34s.\n",
      "07-18-23 07:55:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2649   0.8758   0.5860   0.8937   0.4444   0.5429   \n",
      "valid 0.2846   0.8590   0.5144   0.8855   0.3795   0.5071   \n",
      "test  0.2776   0.8577   0.5499   0.8888   0.4140   0.5018   \n",
      "\n",
      "07-18-23 07:55:Train: [22][0/133]\tBT avg 0.640\tloss avg 0.2357\n",
      "07-18-23 07:55:Train: [22][20/133]\tBT avg 0.595\tloss avg 0.2438\n",
      "07-18-23 07:56:Train: [22][40/133]\tBT avg 0.598\tloss avg 0.2511\n",
      "07-18-23 07:56:Train: [22][60/133]\tBT avg 0.598\tloss avg 0.2599\n",
      "07-18-23 07:56:Train: [22][80/133]\tBT avg 0.598\tloss avg 0.2671\n",
      "07-18-23 07:56:Train: [22][100/133]\tBT avg 0.597\tloss avg 0.2700\n",
      "07-18-23 07:56:Train: [22][120/133]\tBT avg 0.597\tloss avg 0.2702\n",
      "07-18-23 07:57:Epoch 22, lr 0.000990, train loss 0.2711, train time 79.69s, valid time 43.73s, total time 123.42s.\n",
      "07-18-23 07:57:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2650   0.8767   0.5929   0.8949   0.5006   0.5429   \n",
      "valid 0.2868   0.8573   0.5086   0.8794   0.4111   0.4857   \n",
      "test  0.2757   0.8640   0.5666   0.8893   0.4777   0.5161   \n",
      "\n",
      "07-18-23 07:57:Train: [23][0/133]\tBT avg 0.571\tloss avg 0.3769\n",
      "07-18-23 07:57:Train: [23][20/133]\tBT avg 0.595\tloss avg 0.2774\n",
      "07-18-23 07:58:Train: [23][40/133]\tBT avg 0.598\tloss avg 0.2791\n",
      "07-18-23 07:58:Train: [23][60/133]\tBT avg 0.598\tloss avg 0.2733\n",
      "07-18-23 07:58:Train: [23][80/133]\tBT avg 0.599\tloss avg 0.2717\n",
      "07-18-23 07:58:Train: [23][100/133]\tBT avg 0.599\tloss avg 0.2723\n",
      "07-18-23 07:58:Train: [23][120/133]\tBT avg 0.600\tloss avg 0.2716\n",
      "07-18-23 07:59:Epoch 23, lr 0.000989, train loss 0.2707, train time 79.99s, valid time 43.50s, total time 123.49s.\n",
      "07-18-23 07:59:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2771   0.8753   0.5846   0.8897   0.3462   0.5435   \n",
      "valid 0.3000   0.8576   0.5119   0.8794   0.2693   0.4841   \n",
      "test  0.2928   0.8537   0.5375   0.8832   0.3158   0.4839   \n",
      "\n",
      "07-18-23 07:59:Train: [24][0/133]\tBT avg 0.582\tloss avg 0.3120\n",
      "07-18-23 08:00:Train: [24][20/133]\tBT avg 0.603\tloss avg 0.2722\n",
      "07-18-23 08:00:Train: [24][40/133]\tBT avg 0.601\tloss avg 0.2638\n",
      "07-18-23 08:00:Train: [24][60/133]\tBT avg 0.602\tloss avg 0.2683\n",
      "07-18-23 08:00:Train: [24][80/133]\tBT avg 0.601\tloss avg 0.2644\n",
      "07-18-23 08:00:Train: [24][100/133]\tBT avg 0.601\tloss avg 0.2659\n",
      "07-18-23 08:01:Train: [24][120/133]\tBT avg 0.602\tloss avg 0.2665\n",
      "07-18-23 08:01:Epoch 24, lr 0.000987, train loss 0.2688, train time 80.27s, valid time 43.49s, total time 123.76s.\n",
      "07-18-23 08:01:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2626   0.8787   0.5943   0.8944   0.4467   0.5429   \n",
      "valid 0.2824   0.8634   0.5164   0.8803   0.3529   0.5035   \n",
      "test  0.2782   0.8582   0.5480   0.8865   0.4118   0.5125   \n",
      "\n",
      "07-18-23 08:01:[*] Saving files...\n",
      "07-18-23 08:01:Train: [25][0/133]\tBT avg 0.640\tloss avg 0.2144\n",
      "07-18-23 08:02:Train: [25][20/133]\tBT avg 0.603\tloss avg 0.2632\n",
      "07-18-23 08:02:Train: [25][40/133]\tBT avg 0.604\tloss avg 0.2612\n",
      "07-18-23 08:02:Train: [25][60/133]\tBT avg 0.602\tloss avg 0.2587\n",
      "07-18-23 08:02:Train: [25][80/133]\tBT avg 0.601\tloss avg 0.2644\n",
      "07-18-23 08:02:Train: [25][100/133]\tBT avg 0.602\tloss avg 0.2664\n",
      "07-18-23 08:03:Train: [25][120/133]\tBT avg 0.602\tloss avg 0.2653\n",
      "07-18-23 08:03:Epoch 25, lr 0.000985, train loss 0.2668, train time 80.30s, valid time 43.59s, total time 123.88s.\n",
      "07-18-23 08:03:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2704   0.8804   0.6042   0.8921   0.3706   0.5567   \n",
      "valid 0.2953   0.8643   0.5218   0.8789   0.2809   0.5107   \n",
      "test  0.2865   0.8599   0.5543   0.8898   0.3616   0.5036   \n",
      "\n",
      "07-18-23 08:03:Train: [26][0/133]\tBT avg 0.576\tloss avg 0.2946\n",
      "07-18-23 08:04:Train: [26][20/133]\tBT avg 0.601\tloss avg 0.2499\n",
      "07-18-23 08:04:Train: [26][40/133]\tBT avg 0.601\tloss avg 0.2701\n",
      "07-18-23 08:04:Train: [26][60/133]\tBT avg 0.601\tloss avg 0.2671\n",
      "07-18-23 08:04:Train: [26][80/133]\tBT avg 0.601\tloss avg 0.2656\n",
      "07-18-23 08:04:Train: [26][100/133]\tBT avg 0.601\tloss avg 0.2674\n",
      "07-18-23 08:05:Train: [26][120/133]\tBT avg 0.602\tloss avg 0.2663\n",
      "07-18-23 08:06:Epoch 26, lr 0.000983, train loss 0.2673, train time 80.26s, valid time 43.61s, total time 123.87s.\n",
      "07-18-23 08:06:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2588   0.8809   0.6058   0.8965   0.5018   0.5529   \n",
      "valid 0.2832   0.8616   0.5108   0.8794   0.3943   0.4812   \n",
      "test  0.2757   0.8604   0.5647   0.8907   0.4855   0.5071   \n",
      "\n",
      "07-18-23 08:06:Train: [27][0/133]\tBT avg 0.578\tloss avg 0.3296\n",
      "07-18-23 08:06:Train: [27][20/133]\tBT avg 0.599\tloss avg 0.2738\n",
      "07-18-23 08:06:Train: [27][40/133]\tBT avg 0.599\tloss avg 0.2726\n",
      "07-18-23 08:06:Train: [27][60/133]\tBT avg 0.599\tloss avg 0.2721\n",
      "07-18-23 08:06:Train: [27][80/133]\tBT avg 0.599\tloss avg 0.2683\n",
      "07-18-23 08:07:Train: [27][100/133]\tBT avg 0.600\tloss avg 0.2646\n",
      "07-18-23 08:07:Train: [27][120/133]\tBT avg 0.600\tloss avg 0.2657\n",
      "07-18-23 08:08:Epoch 27, lr 0.000980, train loss 0.2661, train time 80.09s, valid time 43.67s, total time 123.76s.\n",
      "07-18-23 08:08:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2572   0.8829   0.6089   0.8968   0.4859   0.5599   \n",
      "valid 0.2796   0.8663   0.5223   0.8827   0.3892   0.5053   \n",
      "test  0.2736   0.8630   0.5646   0.8893   0.4481   0.5177   \n",
      "\n",
      "07-18-23 08:08:[*] Saving files...\n",
      "07-18-23 08:08:Train: [28][0/133]\tBT avg 0.642\tloss avg 0.2455\n",
      "07-18-23 08:08:Train: [28][20/133]\tBT avg 0.610\tloss avg 0.2516\n",
      "07-18-23 08:08:Train: [28][40/133]\tBT avg 0.607\tloss avg 0.2634\n",
      "07-18-23 08:08:Train: [28][60/133]\tBT avg 0.604\tloss avg 0.2639\n",
      "07-18-23 08:08:Train: [28][80/133]\tBT avg 0.602\tloss avg 0.2619\n",
      "07-18-23 08:09:Train: [28][100/133]\tBT avg 0.603\tloss avg 0.2609\n",
      "07-18-23 08:09:Train: [28][120/133]\tBT avg 0.603\tloss avg 0.2620\n",
      "07-18-23 08:10:Epoch 28, lr 0.000978, train loss 0.2633, train time 80.37s, valid time 43.72s, total time 124.09s.\n",
      "07-18-23 08:10:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2577   0.8863   0.6199   0.8994   0.5379   0.5648   \n",
      "valid 0.2821   0.8648   0.5175   0.8789   0.4208   0.4964   \n",
      "test  0.2776   0.8636   0.5652   0.8865   0.4894   0.5214   \n",
      "\n",
      "07-18-23 08:10:Train: [29][0/133]\tBT avg 0.590\tloss avg 0.2055\n",
      "07-18-23 08:10:Train: [29][20/133]\tBT avg 0.604\tloss avg 0.2566\n",
      "07-18-23 08:10:Train: [29][40/133]\tBT avg 0.603\tloss avg 0.2436\n",
      "07-18-23 08:10:Train: [29][60/133]\tBT avg 0.603\tloss avg 0.2510\n",
      "07-18-23 08:10:Train: [29][80/133]\tBT avg 0.602\tloss avg 0.2563\n",
      "07-18-23 08:11:Train: [29][100/133]\tBT avg 0.601\tloss avg 0.2634\n",
      "07-18-23 08:11:Train: [29][120/133]\tBT avg 0.602\tloss avg 0.2630\n",
      "07-18-23 08:12:Epoch 29, lr 0.000976, train loss 0.2618, train time 80.21s, valid time 43.96s, total time 124.17s.\n",
      "07-18-23 08:12:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2541   0.8865   0.6230   0.9003   0.5076   0.5693   \n",
      "valid 0.2779   0.8663   0.5250   0.8855   0.4155   0.5194   \n",
      "test  0.2749   0.8624   0.5617   0.8879   0.4527   0.5122   \n",
      "\n",
      "07-18-23 08:12:[*] Saving files...\n",
      "07-18-23 08:12:Train: [30][0/133]\tBT avg 0.638\tloss avg 0.2679\n",
      "07-18-23 08:12:Train: [30][20/133]\tBT avg 0.604\tloss avg 0.2569\n",
      "07-18-23 08:12:Train: [30][40/133]\tBT avg 0.603\tloss avg 0.2573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18-23 08:12:Train: [30][60/133]\tBT avg 0.602\tloss avg 0.2637\n",
      "07-18-23 08:13:Train: [30][80/133]\tBT avg 0.602\tloss avg 0.2626\n",
      "07-18-23 08:13:Train: [30][100/133]\tBT avg 0.602\tloss avg 0.2623\n",
      "07-18-23 08:13:Train: [30][120/133]\tBT avg 0.602\tloss avg 0.2582\n",
      "07-18-23 08:14:Epoch 30, lr 0.000973, train loss 0.2585, train time 80.26s, valid time 43.74s, total time 124.00s.\n",
      "07-18-23 08:14:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2524   0.8883   0.6271   0.9003   0.4767   0.5650   \n",
      "valid 0.2842   0.8637   0.5138   0.8794   0.3411   0.4912   \n",
      "test  0.2768   0.8597   0.5577   0.8865   0.4203   0.5155   \n",
      "\n",
      "07-18-23 08:14:Train: [31][0/133]\tBT avg 0.576\tloss avg 0.2695\n",
      "07-18-23 08:14:Train: [31][20/133]\tBT avg 0.600\tloss avg 0.2477\n",
      "07-18-23 08:14:Train: [31][40/133]\tBT avg 0.601\tloss avg 0.2650\n",
      "07-18-23 08:14:Train: [31][60/133]\tBT avg 0.601\tloss avg 0.2565\n",
      "07-18-23 08:15:Train: [31][80/133]\tBT avg 0.601\tloss avg 0.2592\n",
      "07-18-23 08:15:Train: [31][100/133]\tBT avg 0.601\tloss avg 0.2553\n",
      "07-18-23 08:15:Train: [31][120/133]\tBT avg 0.602\tloss avg 0.2563\n",
      "07-18-23 08:16:Epoch 31, lr 0.000970, train loss 0.2570, train time 80.15s, valid time 43.94s, total time 124.09s.\n",
      "07-18-23 08:16:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2520   0.8883   0.6289   0.8998   0.5410   0.5708   \n",
      "valid 0.2819   0.8641   0.5216   0.8817   0.4292   0.5107   \n",
      "test  0.2753   0.8664   0.5633   0.8822   0.4645   0.4982   \n",
      "\n",
      "07-18-23 08:16:Train: [32][0/133]\tBT avg 0.564\tloss avg 0.2228\n",
      "07-18-23 08:16:Train: [32][20/133]\tBT avg 0.598\tloss avg 0.2474\n",
      "07-18-23 08:16:Train: [32][40/133]\tBT avg 0.597\tloss avg 0.2565\n",
      "07-18-23 08:16:Train: [32][60/133]\tBT avg 0.598\tloss avg 0.2522\n",
      "07-18-23 08:17:Train: [32][80/133]\tBT avg 0.599\tloss avg 0.2521\n",
      "07-18-23 08:17:Train: [32][100/133]\tBT avg 0.599\tloss avg 0.2552\n",
      "07-18-23 08:17:Train: [32][120/133]\tBT avg 0.599\tloss avg 0.2570\n",
      "07-18-23 08:18:Epoch 32, lr 0.000967, train loss 0.2569, train time 79.86s, valid time 43.63s, total time 123.49s.\n",
      "07-18-23 08:18:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2518   0.8884   0.6277   0.9000   0.4899   0.5681   \n",
      "valid 0.2829   0.8662   0.5226   0.8822   0.3664   0.4932   \n",
      "test  0.2775   0.8616   0.5517   0.8879   0.4262   0.5071   \n",
      "\n",
      "07-18-23 08:18:Train: [33][0/133]\tBT avg 0.577\tloss avg 0.3077\n",
      "07-18-23 08:18:Train: [33][20/133]\tBT avg 0.631\tloss avg 0.2591\n",
      "07-18-23 08:18:Train: [33][40/133]\tBT avg 0.635\tloss avg 0.2572\n",
      "07-18-23 08:19:Train: [33][60/133]\tBT avg 0.637\tloss avg 0.2508\n",
      "07-18-23 08:19:Train: [33][80/133]\tBT avg 0.631\tloss avg 0.2545\n",
      "07-18-23 08:19:Train: [33][100/133]\tBT avg 0.625\tloss avg 0.2545\n",
      "07-18-23 08:19:Train: [33][120/133]\tBT avg 0.621\tloss avg 0.2571\n",
      "07-18-23 08:20:Epoch 33, lr 0.000964, train loss 0.2575, train time 82.50s, valid time 43.69s, total time 126.19s.\n",
      "07-18-23 08:20:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2507   0.8906   0.6242   0.8986   0.4905   0.5664   \n",
      "valid 0.2842   0.8634   0.5156   0.8817   0.3781   0.4964   \n",
      "test  0.2796   0.8606   0.5383   0.8808   0.4057   0.5090   \n",
      "\n",
      "07-18-23 08:20:Train: [34][0/133]\tBT avg 0.637\tloss avg 0.2601\n",
      "07-18-23 08:20:Train: [34][20/133]\tBT avg 0.604\tloss avg 0.2718\n",
      "07-18-23 08:20:Train: [34][40/133]\tBT avg 0.607\tloss avg 0.2616\n",
      "07-18-23 08:21:Train: [34][60/133]\tBT avg 0.605\tloss avg 0.2575\n",
      "07-18-23 08:21:Train: [34][80/133]\tBT avg 0.606\tloss avg 0.2577\n",
      "07-18-23 08:21:Train: [34][100/133]\tBT avg 0.605\tloss avg 0.2571\n",
      "07-18-23 08:21:Train: [34][120/133]\tBT avg 0.604\tloss avg 0.2551\n",
      "07-18-23 08:22:Epoch 34, lr 0.000961, train loss 0.2539, train time 80.54s, valid time 43.66s, total time 124.20s.\n",
      "07-18-23 08:22:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2470   0.8921   0.6428   0.9015   0.5346   0.5757   \n",
      "valid 0.2809   0.8644   0.5188   0.8832   0.4269   0.5000   \n",
      "test  0.2745   0.8658   0.5648   0.8879   0.4768   0.5159   \n",
      "\n",
      "07-18-23 08:22:Train: [35][0/133]\tBT avg 0.592\tloss avg 0.2262\n",
      "07-18-23 08:22:Train: [35][20/133]\tBT avg 0.603\tloss avg 0.2441\n",
      "07-18-23 08:23:Train: [35][40/133]\tBT avg 0.604\tloss avg 0.2438\n",
      "07-18-23 08:23:Train: [35][60/133]\tBT avg 0.604\tloss avg 0.2497\n",
      "07-18-23 08:23:Train: [35][80/133]\tBT avg 0.605\tloss avg 0.2497\n",
      "07-18-23 08:23:Train: [35][100/133]\tBT avg 0.605\tloss avg 0.2526\n",
      "07-18-23 08:23:Train: [35][120/133]\tBT avg 0.605\tloss avg 0.2528\n",
      "07-18-23 08:24:Epoch 35, lr 0.000958, train loss 0.2523, train time 80.54s, valid time 43.13s, total time 123.67s.\n",
      "07-18-23 08:24:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2478   0.8937   0.6457   0.9014   0.4720   0.5818   \n",
      "valid 0.2884   0.8624   0.4989   0.8775   0.3130   0.4806   \n",
      "test  0.2781   0.8613   0.5507   0.8893   0.4061   0.4982   \n",
      "\n",
      "07-18-23 08:24:Train: [36][0/133]\tBT avg 0.570\tloss avg 0.1865\n",
      "07-18-23 08:24:Train: [36][20/133]\tBT avg 0.600\tloss avg 0.2438\n",
      "07-18-23 08:25:Train: [36][40/133]\tBT avg 0.600\tloss avg 0.2388\n",
      "07-18-23 08:25:Train: [36][60/133]\tBT avg 0.607\tloss avg 0.2440\n",
      "07-18-23 08:25:Train: [36][80/133]\tBT avg 0.624\tloss avg 0.2462\n",
      "07-18-23 08:25:Train: [36][100/133]\tBT avg 0.627\tloss avg 0.2498\n",
      "07-18-23 08:25:Train: [36][120/133]\tBT avg 0.630\tloss avg 0.2516\n",
      "07-18-23 08:26:Epoch 36, lr 0.000955, train loss 0.2512, train time 84.56s, valid time 45.12s, total time 129.68s.\n",
      "07-18-23 08:26:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2449   0.8976   0.6509   0.9007   0.4704   0.5897   \n",
      "valid 0.2852   0.8623   0.5157   0.8770   0.3085   0.5035   \n",
      "test  0.2773   0.8623   0.5480   0.8879   0.3969   0.5036   \n",
      "\n",
      "07-18-23 08:26:Train: [37][0/133]\tBT avg 0.590\tloss avg 0.2810\n",
      "07-18-23 08:27:Train: [37][20/133]\tBT avg 0.650\tloss avg 0.2520\n",
      "07-18-23 08:27:Train: [37][40/133]\tBT avg 0.669\tloss avg 0.2458\n",
      "07-18-23 08:27:Train: [37][60/133]\tBT avg 0.671\tloss avg 0.2495\n",
      "07-18-23 08:27:Train: [37][80/133]\tBT avg 0.666\tloss avg 0.2466\n",
      "07-18-23 08:27:Train: [37][100/133]\tBT avg 0.655\tloss avg 0.2470\n",
      "07-18-23 08:28:Train: [37][120/133]\tBT avg 0.658\tloss avg 0.2480\n",
      "07-18-23 08:29:Epoch 37, lr 0.000951, train loss 0.2493, train time 87.22s, valid time 44.60s, total time 131.82s.\n",
      "07-18-23 08:29:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2426   0.8975   0.6591   0.9051   0.5592   0.5949   \n",
      "valid 0.2822   0.8649   0.5051   0.8761   0.3963   0.4929   \n",
      "test  0.2777   0.8623   0.5555   0.8865   0.4805   0.5250   \n",
      "\n",
      "07-18-23 08:29:Train: [38][0/133]\tBT avg 0.635\tloss avg 0.2326\n",
      "07-18-23 08:29:Train: [38][20/133]\tBT avg 0.607\tloss avg 0.2479\n",
      "07-18-23 08:29:Train: [38][40/133]\tBT avg 0.620\tloss avg 0.2415\n",
      "07-18-23 08:29:Train: [38][60/133]\tBT avg 0.620\tloss avg 0.2484\n",
      "07-18-23 08:29:Train: [38][80/133]\tBT avg 0.618\tloss avg 0.2507\n",
      "07-18-23 08:30:Train: [38][100/133]\tBT avg 0.617\tloss avg 0.2489\n",
      "07-18-23 08:30:Train: [38][120/133]\tBT avg 0.616\tloss avg 0.2491\n",
      "07-18-23 08:31:Epoch 38, lr 0.000947, train loss 0.2489, train time 82.12s, valid time 43.97s, total time 126.09s.\n",
      "07-18-23 08:31:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2404   0.8987   0.6589   0.9042   0.5557   0.5931   \n",
      "valid 0.2825   0.8652   0.5097   0.8813   0.4308   0.5000   \n",
      "test  0.2764   0.8639   0.5568   0.8841   0.4639   0.5000   \n",
      "\n",
      "07-18-23 08:31:Train: [39][0/133]\tBT avg 0.589\tloss avg 0.2170\n",
      "07-18-23 08:31:Train: [39][20/133]\tBT avg 0.654\tloss avg 0.2394\n",
      "07-18-23 08:31:Train: [39][40/133]\tBT avg 0.668\tloss avg 0.2403\n",
      "07-18-23 08:31:Train: [39][60/133]\tBT avg 0.671\tloss avg 0.2424\n",
      "07-18-23 08:32:Train: [39][80/133]\tBT avg 0.677\tloss avg 0.2391\n",
      "07-18-23 08:32:Train: [39][100/133]\tBT avg 0.671\tloss avg 0.2437\n",
      "07-18-23 08:32:Train: [39][120/133]\tBT avg 0.673\tloss avg 0.2467\n",
      "07-18-23 08:33:Epoch 39, lr 0.000944, train loss 0.2493, train time 89.85s, valid time 45.42s, total time 135.26s.\n",
      "07-18-23 08:33:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2431   0.9023   0.6607   0.9018   0.4588   0.5943   \n",
      "valid 0.2879   0.8640   0.5108   0.8770   0.2935   0.5036   \n",
      "test  0.2849   0.8556   0.5320   0.8851   0.3688   0.4946   \n",
      "\n",
      "07-18-23 08:33:[*] Overfitting... Stop!\n",
      "07-18-23 08:33:=============== eval ===============\n",
      "07-18-23 08:33:[*] Model loaded!\n",
      "07-18-23 08:33:[*] skipped: 0  loaded: 1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18-23 08:34:\n",
      "      bceloss  auroc    auprc    accu     f1       minpse   \n",
      "train 0.2541   0.8865   0.6230   0.9003   0.5076   0.5693   \n",
      "valid 0.2779   0.8663   0.5250   0.8855   0.4155   0.5194   \n",
      "test  0.2749   0.8624   0.5617   0.8879   0.4527   0.5122   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTrainer at 0x7f44383a2e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport model\n",
    "\n",
    "args.debug = False\n",
    "args.gpu = \"3,4,5\"\n",
    "\n",
    "ModelTrainer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f8ef7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}